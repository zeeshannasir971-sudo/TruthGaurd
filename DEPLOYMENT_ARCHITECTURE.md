# TruthGuard Deployment Architecture

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DEVELOPMENT                              â”‚
â”‚                                                                  â”‚
â”‚  1. Train Model Locally                                         â”‚
â”‚     python -m src.ml.pipeline                                   â”‚
â”‚     â†“                                                            â”‚
â”‚  2. Generate .pkl files (85MB total)                            â”‚
â”‚     â€¢ fake_news_model.pkl (50MB)                                â”‚
â”‚     â€¢ tfidf_word_vectorizer.pkl (20MB)                          â”‚
â”‚     â€¢ tfidf_char_vectorizer.pkl (15MB)                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UPLOAD TO HUGGING FACE                        â”‚
â”‚                                                                  â”‚
â”‚  python upload_to_huggingface.py                                â”‚
â”‚  â†“                                                               â”‚
â”‚  Models stored at:                                              â”‚
â”‚  https://huggingface.co/YOUR_USERNAME/truthguard-models/        â”‚
â”‚                                                                  â”‚
â”‚  Public URLs:                                                   â”‚
â”‚  â€¢ .../fake_news_model.pkl                                      â”‚
â”‚  â€¢ .../tfidf_word_vectorizer.pkl                                â”‚
â”‚  â€¢ .../tfidf_char_vectorizer.pkl                                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PUSH TO GITHUB                              â”‚
â”‚                                                                  â”‚
â”‚  git add .                                                       â”‚
â”‚  git commit -m "Ready for deployment"                           â”‚
â”‚  git push origin main                                            â”‚
â”‚                                                                  â”‚
â”‚  Repository contains (5MB):                                     â”‚
â”‚  âœ… All Python code                                             â”‚
â”‚  âœ… download_assets.py                                          â”‚
â”‚  âœ… requirements.txt                                            â”‚
â”‚  âœ… vercel.json / netlify.toml                                  â”‚
â”‚  âŒ NO .pkl files                                               â”‚
â”‚  âŒ NO .csv files                                               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VERCEL/NETLIFY BUILD                          â”‚
â”‚                                                                  â”‚
â”‚  Step 1: Clone from GitHub                                      â”‚
â”‚  â”œâ”€ Get all code files                                          â”‚
â”‚  â””â”€ No model files yet                                          â”‚
â”‚                                                                  â”‚
â”‚  Step 2: Install dependencies                                   â”‚
â”‚  â””â”€ pip install -r requirements.txt                             â”‚
â”‚                                                                  â”‚
â”‚  Step 3: Download models                                        â”‚
â”‚  â””â”€ python src/scripts/download_assets.py                       â”‚
â”‚     â”œâ”€ Check if models exist                                    â”‚
â”‚     â”œâ”€ Download from Hugging Face                               â”‚
â”‚     â”œâ”€ Save to src/ml/artifacts/                                â”‚
â”‚     â””â”€ Verify all files present                                 â”‚
â”‚                                                                  â”‚
â”‚  Step 4: Start application                                      â”‚
â”‚  â””â”€ python app.py                                               â”‚
â”‚     â”œâ”€ Run startup.py                                           â”‚
â”‚     â”œâ”€ Load models into memory                                  â”‚
â”‚     â””â”€ Start Flask server                                       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PRODUCTION RUNTIME                          â”‚
â”‚                                                                  â”‚
â”‚  Request Flow:                                                  â”‚
â”‚                                                                  â”‚
â”‚  User Request                                                   â”‚
â”‚      â†“                                                           â”‚
â”‚  POST /analyze                                                  â”‚
â”‚      â†“                                                           â”‚
â”‚  load_model()                                                   â”‚
â”‚      â”œâ”€ Check cache                                             â”‚
â”‚      â”œâ”€ If cached: return immediately                           â”‚
â”‚      â””â”€ If not: load from disk (one-time)                       â”‚
â”‚      â†“                                                           â”‚
â”‚  predict(text)                                                  â”‚
â”‚      â”œâ”€ Preprocess text                                         â”‚
â”‚      â”œâ”€ Extract features                                        â”‚
â”‚      â”œâ”€ Run ML prediction                                       â”‚
â”‚      â””â”€ Return result                                           â”‚
â”‚      â†“                                                           â”‚
â”‚  Response (JSON)                                                â”‚
â”‚      â””â”€ {label, prob_fake, sentiment}                           â”‚
â”‚                                                                  â”‚
â”‚  Performance:                                                   â”‚
â”‚  â€¢ First request: 2-5s (load models)                            â”‚
â”‚  â€¢ Subsequent: <100ms (cached)                                  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ File Organization

### What's in GitHub (Small - 5MB)

```
project/
â”œâ”€â”€ app.py                              âœ… Flask app
â”œâ”€â”€ startup.py                          âœ… Model download check
â”œâ”€â”€ requirements.txt                    âœ… Dependencies
â”œâ”€â”€ vercel.json                         âœ… Vercel config
â”œâ”€â”€ netlify.toml                        âœ… Netlify config
â”œâ”€â”€ .gitignore                          âœ… Excludes large files
â”œâ”€â”€ upload_to_huggingface.py           âœ… Upload script
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ pipeline.py                âœ… ML logic
â”‚   â”‚   â””â”€â”€ artifacts/
â”‚   â”‚       â”œâ”€â”€ .gitkeep               âœ… Keep directory
â”‚   â”‚       â”œâ”€â”€ *.pkl                  âŒ NOT in Git
â”‚   â”‚       â””â”€â”€ (downloaded on deploy)
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ download_assets.py         âœ… Download logic
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ fetch.py                   âœ… Web scraping
â”‚   â”‚   â”œâ”€â”€ preprocess.py              âœ… Text processing
â”‚   â”‚   â”œâ”€â”€ sentiment.py               âœ… Sentiment
â”‚   â”‚   â””â”€â”€ search.py                  âœ… Search
â”‚   â”‚
â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â””â”€â”€ routes.py                  âœ… API routes
â”‚   â”‚
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ .gitkeep                   âœ… Keep directory
â”‚       â””â”€â”€ *.csv                      âŒ NOT in Git
â”‚
â””â”€â”€ frontend/                           âœ… Next.js app
    â”œâ”€â”€ app/
    â”œâ”€â”€ components/
    â””â”€â”€ package.json
```

### What's in Hugging Face (Large - 85MB)

```
truthguard-models/
â”œâ”€â”€ fake_news_model.pkl                 ğŸ“¦ 50MB
â”œâ”€â”€ tfidf_word_vectorizer.pkl          ğŸ“¦ 20MB
â””â”€â”€ tfidf_char_vectorizer.pkl          ğŸ“¦ 15MB
```

## ğŸ”„ Deployment Workflow

### Initial Setup (One-Time)

```bash
# 1. Train model locally
python -m src.ml.pipeline

# 2. Install Hugging Face CLI
pip install huggingface_hub

# 3. Login to Hugging Face
huggingface-cli login

# 4. Upload models
python upload_to_huggingface.py

# 5. Update download_assets.py with your URLs

# 6. Test download
rm src/ml/artifacts/*.pkl
python src/scripts/download_assets.py

# 7. Commit and push
git add .
git commit -m "Ready for deployment"
git push origin main
```

### Every Deployment

```bash
# 1. Make code changes
# 2. Commit and push
git push origin main

# 3. Vercel/Netlify automatically:
#    - Clones repo
#    - Installs dependencies
#    - Downloads models
#    - Deploys app
```

## ğŸ¯ Key Benefits

### âœ… Works on Vercel/Netlify
- No Git LFS needed
- No large file commits
- Automatic model download
- Fast deployment

### âœ… Efficient Storage
- GitHub: 5MB (code only)
- Hugging Face: 85MB (models)
- Total: 90MB (properly separated)

### âœ… Fast Performance
- Models cached in memory
- <100ms prediction time
- Scales automatically

### âœ… Easy Updates
- Update code: Push to GitHub
- Update models: Upload to Hugging Face
- Both independent

## ğŸš€ Deployment Platforms

### Backend Options

| Platform | Pros | Cons | Cost |
|----------|------|------|------|
| **Vercel** | Easy, fast, Python support | Function size limits | Free tier |
| **Railway** | No timeouts, simple | Slightly slower | Free tier |
| **Render** | Reliable, good docs | Cold starts | Free tier |
| **Heroku** | Mature, stable | Slower deploys | $7/mo |

### Frontend Options

| Platform | Pros | Cons | Cost |
|----------|------|------|------|
| **Vercel** | Best for Next.js | None | Free tier |
| **Netlify** | Easy, fast | None | Free tier |
| **AWS Amplify** | AWS integration | More complex | Free tier |

## ğŸ“Š Performance Metrics

### Build Time
```
Clone repo:          10s
Install deps:        60s
Download models:     30s
Start app:          10s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:              ~2min
```

### Runtime Performance
```
Cold start:         2-5s (first request)
Warm requests:      <100ms
Model loading:      One-time per instance
Predictions:        <100ms each
```

### Resource Usage
```
Memory:             ~200MB (with models loaded)
Disk:               ~90MB (code + models)
CPU:                Low (inference only)
```

## ğŸ”’ Security

### âœ… Secure Practices
- Models on public Hugging Face (read-only)
- No secrets in code
- Environment variables for config
- CORS properly configured

### âŒ Avoid
- Committing .pkl files to Git
- Hardcoding API keys
- Training during deployment
- Loading large CSVs in functions

## ğŸ‰ Success Criteria

Your deployment is successful when:

- âœ… GitHub repo < 10MB
- âœ… Models on Hugging Face
- âœ… Build completes in < 3 minutes
- âœ… App starts successfully
- âœ… First request works (may be slow)
- âœ… Subsequent requests < 100ms
- âœ… No errors in logs
- âœ… Frontend connects to backend

## ğŸ“š Documentation Files

- `DEPLOY_NOW.md` - Quick 5-step guide
- `DEPLOYMENT_STRATEGY.md` - Complete strategy
- `DEPLOYMENT_GUIDE.md` - Detailed instructions
- `DEPLOYMENT_ARCHITECTURE.md` - This file

## ğŸŠ You're Ready!

Your TruthGuard project now has:

âœ… Proper separation of code and assets
âœ… Automatic model downloading
âœ… Vercel/Netlify compatibility
âœ… Fast deployment
âœ… Scalable architecture
âœ… Production-ready setup

**Deploy with confidence!** ğŸš€
